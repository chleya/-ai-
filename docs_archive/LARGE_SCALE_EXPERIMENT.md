# 大规模扩展实验补充报告
## Large-Scale Expansion Experiments

**生成日期**: 2026-02-07

---

## 实验目标

验证小规模结论（LTD效果~70%）在大规模系统（10+节点，N=100-500）中的适用性。

---

## 实验配置

| 阶段 | 节点数 | N | 演化步数 | 预期 |
|------|---------|---|----------|------|
| 基线 | 3 | 50 | 2000 | ~70% |
| 小规模 | 5-10 | 100 | 2000 | ~60-70% |
| 中规模 | 20 | 200 | 3000 | ~50-60% |
| 大规模 | 50 | 500 | 3000 | ~40-50% |

---

## 理论分析

### 1. 维度效应

**假设**：LTD效果随维度N增加而衰减

**理论依据**：
- 高维空间中，随机向量几乎正交
- 错误吸引子与正确吸引子的干涉减弱
- 系统更依赖局部信息

**数学表达**：

$$P(\text{正交}) \approx 1 - \frac{1}{N}$$

当N=500时，$P(\text{正交}) \approx 0.998$

### 2. 节点数效应

**假设**：增加模糊节点会稀释LTD效果

**机制**：
- 每个模糊节点引入额外噪声
- 耦合信号变得更复杂
- 收敛时间增加

**估计公式**：

$$E[\text{正确率}] \approx p_{good} - \frac{n_{fuzzy}}{N} \cdot \sigma_{noise}$$

---

## 实验设计

### 大规模LTD测试

```python
def run_large_scale_test(N, n_nodes, steps, n_tests=15):
    """测试LTD在大规模系统中的效果"""
    
    # 1. 创建正确和错误吸引子
    W_good = random_weights(N)
    W_bad = random_weights(N)
    
    # 2. 学习阶段
    for _ in range(steps):
        x_good = learn(W_good, P)  # 正确模式
        x_bad = learn(W_bad, -P)   # 错误模式
    
    # 3. LTD阶段
    W_bad = apply_ltd(W_bad)  # 破坏错误吸引子
    
    # 4. 测试阶段
    return test_consensus(W_good, W_bad, n_nodes)
```

### 对照配置

| 配置 | 正确节点 | 模糊节点 | 错误节点 |
|------|----------|----------|----------|
| 基线 | 1 | 1 | 1 |
| 小规模 | 2 | 5 | 1 |
| 中规模 | 5 | 15 | 1 |
| 大规模 | 10 | 40 | 1 |

---

## 预期结果

### 场景1：LTD有效扩展

| 规模 | 预期正确率 | 置信度 |
|------|-------------|--------|
| 基线 (3节点) | ~70% | 高 |
| 小规模 (10节点) | ~65% | 中 |
| 中规模 (20节点) | ~60% | 中 |
| 大规模 (50节点) | ~55% | 低 |

**判定标准**：LTD效果衰减 < 30%

### 场景2：LTD效果衰减

| 规模 | 预期正确率 | 衰减 |
|------|-------------|------|
| 基线 (3节点) | ~70% | - |
| 小规模 (10节点) | ~50% | -20% |
| 中规模 (20节点) | ~40% | -30% |
| 大规模 (50节点) | ~30% | -40% |

---

## 关键假设

### 假设1：能量景观光滑性

高维空间中，错误吸引子与正确吸引子之间的能量壁垒更高，LTD需要更强的负增益才能跨越。

$$\Delta E_{LTD} \propto \frac{1}{N}$$

### 假设2：噪声平均效应

多个模糊节点的噪声趋向于相互抵消：

$$E[\sum_{i=1}^{n} \xi_i] = 0$$
$$Var(\sum_{i=1}^{n} \xi_i) = n \cdot \sigma^2$$

---

## 失败模式分析

### 模式1：LTD过度破坏

**症状**：正确吸引子也被削弱

**原因**：
- LTD阈值设置不当
- 学习率η过大

**解决方案**：
- 降低η
- 增加LTD选择性

### 模式2：收敛太慢

**症状**：300步内无法收敛

**原因**：
- 节点数过多
- 耦合强度不足

**解决方案**：
- 增加演化步数
- 增强耦合

### 模式3：能量壁垒过高

**症状**：LTD后系统仍收敛到错误吸引子

**原因**：
- 错误吸引子过深
- N过大

**解决方案**：
- 增加LTD强度
- 多次LTD迭代

---

## 实验参数

### 关键参数

| 参数 | 值 | 说明 |
|------|---|------|
| N | 100-500 | 系统维度 |
| n_nodes | 5-50 | 节点数 |
| steps | 1500-3000 | 演化步数 |
| n_tests | 10-15 | 随机种子数 |
| η_LTD | 0.5 | LTD学习率 |

### 停止条件

1. 达到最大迭代次数
2. 正确率稳定在±5%范围内
3. 超过预设时间限制

---

## 数据分析

### 统计方法

| 指标 | 方法 | 说明 |
|------|------|------|
| 平均值 | 算术平均 | 中心趋势 |
| 标准差 | σ | 离散程度 |
| 置信区间 | 95% CI | 统计显著性 |
| p值 | t-test | 显著性检验 |

### 比较方法

$$H_0: \mu_{LTD} = \mu_{baseline}$$
$$H_1: \mu_{LTD} > \mu_{baseline}$$

显著性水平：α = 0.05

---

## 预期贡献

### 理论贡献

1. **维度效应**：揭示N对LTD效果的影响
2. **规模效应**：量化节点数与效果的关系
3. **边界条件**：找到LTD失效的临界点

### 实践贡献

1. **设计指南**：提供LTD参数选择建议
2. **规模预估**：预测大规模系统的性能
3. **优化方向**：指出改进LTD的途径

---

## 结果解释

### 场景1：LTD有效

如果大规模实验中LTD保持50%+正确率：

> "LTD机制具有良好的可扩展性，可应用于大规模边缘计算系统。"

### 场景2：LTD衰减

如果LTD效果显著下降：

> "LTD的效果受限于系统规模和维度。大规模系统需要更强的LTD或其他机制。"

---

## 后续实验

### 1. 维度扫描

```python
for N in [100, 200, 500, 1000]:
    result = run_test(N, nodes=10, steps=3000)
    print(f"N={N}: {result}%")
```

### 2. 节点数扫描

```python
for nodes in [5, 10, 20, 50, 100]:
    result = run_test(N=200, nodes=nodes, steps=3000)
    print(f"nodes={nodes}: {result}%")
```

### 3. LTD参数优化

```python
for eta in [0.1, 0.3, 0.5, 0.7, 1.0]:
    result = run_test(eta=eta)
    print(f"η={eta}: {result}%")
```

---

## 时间估算

| 实验 | 预期时间 |
|------|----------|
| 小规模 (N=100, 10节点) | ~30秒 |
| 中规模 (N=200, 20节点) | ~1分钟 |
| 大规模 (N=500, 50节点) | ~3分钟 |
| 完整扫描 | ~10分钟 |

---

## 风险评估

| 风险 | 影响 | 概率 | 应对 |
|------|------|------|------|
| 计算超时 | 实验无法完成 | 中 | 减少n_tests |
| 内存溢出 | 系统崩溃 | 低 | 降低N |
| 结果不稳定 | 无法得出结论 | 中 | 增加n_tests |

---

## 成功标准

### 最低成功

- 至少一个大规模配置完成
- LTD正确率 > 40%

### 部分成功

- 3个配置完成
- LTD效果 > 基线20%

### 完全成功

- 全部配置完成
- 找到LTD效果与规模的数学关系

---

*实验正在运行中...*
*结果将更新到 results/large_scale_expansion.json*
